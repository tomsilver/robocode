{
  "mean_eval_reward": -28.0,
  "mean_eval_steps": 28.0,
  "solve_rate": 1.0,
  "num_train_tasks": 10,
  "num_eval_tasks": 10,
  "per_episode": [
    {
      "total_reward": -17.0,
      "num_steps": 17,
      "solved": true
    },
    {
      "total_reward": -20.0,
      "num_steps": 20,
      "solved": true
    },
    {
      "total_reward": -8.0,
      "num_steps": 8,
      "solved": true
    },
    {
      "total_reward": -1.0,
      "num_steps": 1,
      "solved": true
    },
    {
      "total_reward": -50.0,
      "num_steps": 50,
      "solved": true
    },
    {
      "total_reward": -3.0,
      "num_steps": 3,
      "solved": true
    },
    {
      "total_reward": -23.0,
      "num_steps": 23,
      "solved": true
    },
    {
      "total_reward": -9.0,
      "num_steps": 9,
      "solved": true
    },
    {
      "total_reward": -25.0,
      "num_steps": 25,
      "solved": true
    },
    {
      "total_reward": -124.0,
      "num_steps": 124,
      "solved": true
    }
  ]
}