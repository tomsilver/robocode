{
  "mean_eval_reward": -477.5,
  "mean_eval_steps": 477.5,
  "solve_rate": 0.9,
  "num_train_tasks": 10,
  "num_eval_tasks": 10,
  "per_episode": [
    {
      "total_reward": -811.0,
      "num_steps": 811,
      "solved": true
    },
    {
      "total_reward": -858.0,
      "num_steps": 858,
      "solved": true
    },
    {
      "total_reward": -90.0,
      "num_steps": 90,
      "solved": true
    },
    {
      "total_reward": -380.0,
      "num_steps": 380,
      "solved": true
    },
    {
      "total_reward": -418.0,
      "num_steps": 418,
      "solved": true
    },
    {
      "total_reward": -1000.0,
      "num_steps": 1000,
      "solved": false
    },
    {
      "total_reward": -88.0,
      "num_steps": 88,
      "solved": true
    },
    {
      "total_reward": -193.0,
      "num_steps": 193,
      "solved": true
    },
    {
      "total_reward": -918.0,
      "num_steps": 918,
      "solved": true
    },
    {
      "total_reward": -19.0,
      "num_steps": 19,
      "solved": true
    }
  ]
}