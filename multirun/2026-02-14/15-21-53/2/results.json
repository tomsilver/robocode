{
  "mean_eval_reward": -34.8,
  "mean_eval_steps": 34.8,
  "solve_rate": 1.0,
  "num_train_tasks": 10,
  "num_eval_tasks": 10,
  "per_episode": [
    {
      "total_reward": -19.0,
      "num_steps": 19,
      "solved": true
    },
    {
      "total_reward": -17.0,
      "num_steps": 17,
      "solved": true
    },
    {
      "total_reward": -68.0,
      "num_steps": 68,
      "solved": true
    },
    {
      "total_reward": -82.0,
      "num_steps": 82,
      "solved": true
    },
    {
      "total_reward": -1.0,
      "num_steps": 1,
      "solved": true
    },
    {
      "total_reward": -52.0,
      "num_steps": 52,
      "solved": true
    },
    {
      "total_reward": -16.0,
      "num_steps": 16,
      "solved": true
    },
    {
      "total_reward": -14.0,
      "num_steps": 14,
      "solved": true
    },
    {
      "total_reward": -62.0,
      "num_steps": 62,
      "solved": true
    },
    {
      "total_reward": -17.0,
      "num_steps": 17,
      "solved": true
    }
  ]
}